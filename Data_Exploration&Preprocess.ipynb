{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries\n",
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "import datetime as dt\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betty\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (9,412) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "######################################################################### download\n",
    "# load the csv file and save it into the dataframe donors\n",
    "donors = pd.read_csv(os.path.join(r\"C:\\Users\\betty\\OneDrive\\Documentos\\GitHub\\Project\\donors.csv\"), index_col = 0)\n",
    "#donors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check id unique\n",
    "#donors['CONTROLN'].unique().size #95412\n",
    "donors.set_index('CONTROLN',drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_original=donors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicated observations\n",
    "#donors.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pandas profiling\n",
    "#ProfileReport(donors, minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on previous analysis, we will drop the following columns (justification provided in report appendix??)\n",
    "\n",
    "drop_columns =  (['OSOURCE','PVASTATE','NOEXCH','HOMEOWNR','MALEMILI','MALEVET','VIETVETS','WWIIVETS','LOCALGOV','STATEGOV','FEDGOV','GEOCODE','LIFESRC','HPHONE_D','GEOCODE2'] +\n",
    "                #drop all ADATE columns except last promotion 17NK        \n",
    "                list(donors.filter(regex='^ADATE_',axis=1).columns.values)[1:] +\n",
    "                #drop all the RFA columns\n",
    "                list(donors.filter(regex='^RFA_',axis=1).columns.values)[:-3] +\n",
    "                #drop all the RDATE columns\n",
    "                list(donors.filter(regex='^RDATE_',axis=1).columns.values) + \n",
    "                #drop all the RAMNT columns\n",
    "                list(donors.filter(regex='^RAMNT_',axis=1).columns.values))\n",
    "                \n",
    "donors.drop(drop_columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat column MAJOR to see if the information matches the one in the column  MDMAUD, regarding no major donors, and if yes delete MAJOR\n",
    "\n",
    "#check if all the donors with blank cells (not a major donor) under MAJOR correspond a donors with X value (meaning not a major donor) under  MDMAUD\n",
    "donors.loc[donors[\"MAJOR\"] ==\" \"][[\"MDMAUD\"]] [\"MDMAUD\"].value_counts() #We can conclude that all blank values under column Major (that represent the not major donor) have a correspondent X in the column MDMAUD, so the column Major can be deleted \n",
    "\n",
    "#drop column MAJOR\n",
    "donors.drop(\"MAJOR\",axis=1, inplace=True)\n",
    "\n",
    "# Also drop MDMAUD since the information is already separated in RFA\n",
    "donors.drop(\"MDMAUD\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up the TCODE column\n",
    "#typecast it into a string for treatment\n",
    "donors['TCODE']=donors['TCODE'].astype(str)\n",
    "donors['TCODE'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat T-code column to only keep the first 3 letters\n",
    "\n",
    "donors['TCODE']=donors['TCODE'].map(lambda x: x[:-3] if '002' in x or '004' in x or '028' in x else x) # same code - same meaning without the gender and plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat high cardinality choosing the most frequent states and group others as 'other'\n",
    "#donors['STATE'].value_counts()\n",
    "state8 = donors['STATE'].value_counts()[:8].index.tolist()\n",
    "donors['STATE'] = np.where(~donors['STATE'].isin(state8), 'Other', donors['STATE'])\n",
    "\n",
    "#drop ZIP - redundant\n",
    "donors.drop('ZIP', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of data with a Bad address\n",
    "#(len(donors_original[donors_original['MAILCODE']=='B'])/len(donors_original))*100 #1.466% 1399 donors\n",
    "\n",
    "#since it's such a small percentage of the dataset and given the time & resource constraint for the project\n",
    "#we decided to drop them\n",
    "filter_to_drop = donors_original['MAILCODE']=='B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the rows or donors which have a Bad address \n",
    "donors = donors[donors['MAILCODE']!='B']\n",
    "\n",
    "#now we can drop the mailcode column because it no longer adds information to the data\n",
    "donors.drop(['MAILCODE'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the type of the DOB column\n",
    "#donors['DOB'].dtypes #it's a string\n",
    "#treat the DOB to only show the year without the day or month\n",
    "donors['DOB'] = donors['DOB'].str[:4]\n",
    "\n",
    "#donors['DOB'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create AGE \n",
    "donors['AGE'] = 2020 - donors['DOB'].astype('float')\n",
    "donors.drop('DOB',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do same thing for original data\n",
    "donors_original['DOB'] = donors_original['DOB'].str[:4]\n",
    "donors_original['AGE'] = 2020 - donors_original['DOB'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably parents donating with children name - can bias the clustering \n",
    "#donors[(donors['AGE']<16)]\n",
    "donors = donors[~(donors['AGE']<16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_drop = filter_to_drop | (donors_original['AGE']<16)\n",
    "#len(donors_original[filter_to_drop])/len(donors_original) *100 #1.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[(donors_original['AGE']<16)])#/len(donors_original) *100 # we only have 425 donors younger than 16 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat file flags columns with blanks and Xs to 0s and 1s\n",
    "replaceFlag_dict = {' ': 0,'X': 1}\n",
    "# Filtering the columns that start with 'REC' - record columns\n",
    "rec_columns = donors.filter(regex='^REC',axis=1).columns.values\n",
    "for rec in rec_columns:\n",
    "    donors[rec].replace(replaceFlag_dict, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that it now only includes values 0 and 1\n",
    "#for rec in rec_columns : \n",
    "#    print(donors[rec].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '28', '3', '1002', '42', '4', '18', '980', '14',\n",
       "       '28028', '72', '22', '13002', '23', '45', '24', '4002', '30', '13',\n",
       "       '202', '136', '72002', '96', '116', '100', '4004', '39002', '61',\n",
       "       '47', '36', '228', '14002', '6', '6400', '40', '25', '21', '12',\n",
       "       '58002', '134', '18002', '38', '9', '76', '50', '27', '93', '17',\n",
       "       '94', '7', '44', '24002', '22002'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling missing values of the gender column\n",
    "#trying to associate it with tcode\n",
    "donors['TCODE_original'] =donors_original['TCODE'].astype(str)\n",
    "donors['TCODE_original'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_list = ['2','3','28028','42']\n",
    "male_list = ['1','36','40']\n",
    "donors['gender_code'] = donors['TCODE_original'].map(lambda x: 'F' if '002' in x or x in female_list else 'M' if x in male_list else ' ')\n",
    "#donors['gender_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        3320\n",
       "1002     1489\n",
       "1         241\n",
       "4002       34\n",
       "3          32\n",
       "39002       6\n",
       "13002       4\n",
       "28028       2\n",
       "42          1\n",
       "18002       1\n",
       "24002       1\n",
       "58002       1\n",
       "22002       1\n",
       "Name: TCODE_original, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check association with the categories F and M \n",
    "GENDER_vs_gender= donors[(donors.GENDER.isin(['F','M']))&(donors.gender_code!=' ')][['TCODE_original','GENDER','gender_code']]\n",
    "#adding a binary column with 1 if there's no match \n",
    "GENDER_vs_gender['inequality'] = np.where(GENDER_vs_gender['GENDER'] == GENDER_vs_gender['gender_code'], 0, 1)\n",
    "\n",
    "#different gender association\n",
    "#GENDER_vs_gender[GENDER_vs_gender['inequality']==1]\n",
    "GENDER_vs_gender[GENDER_vs_gender['inequality']==1]['TCODE_original'].value_counts()\n",
    "# there a lot of errors associating the gender with tcode (misters has females and misses as males, for example) \n",
    "# since we dont know the origin of the error we are not going to do this association given the assumptions that we need to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns (used just to do this association)\n",
    "# AND tcode has it is lacking information and may not be very useful\n",
    "donors.drop(['TCODE','TCODE_original','gender_code'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we decided to replace the missing values with category U - unknown\n",
    "# replace blanks, C, and A in gender column with U as they are all unknown values\n",
    "replaceGender_dict = dict.fromkeys([' ', 'C', 'A','J'], 'U')\n",
    "#print(replaceGender_dict)\n",
    "donors['GENDER'].replace(replaceGender_dict,inplace= True)\n",
    "\n",
    "#check that it now only includes values that are listed/categorized in the meta data\n",
    "#donors['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat the PEPSTRFL column to have 0s and 1s instead of blanks and Xs\n",
    "donors['PEPSTRFL'].replace(replaceFlag_dict, inplace= True)\n",
    "#check that it now only includes values 0 and 1\n",
    "#donors['PEPSTRFL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associating NUMCHILD WITH 'CHILD03', 'CHILD07', 'CHILD12', 'CHILD18'\n",
    "childAge_columns = donors.filter(regex='^CHILD', axis=1).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we noticed that not all the blanks of NUMCHILD are 0 children. Since we have some of CHILD_ variables filled \n",
    "# so for this blanks we are going to put the least number of children this donor has\n",
    "\n",
    "# If we have this values on CHILD__ we have at least __ child\n",
    "sum_dict = {\"B\":2,\"M\":1,\"F\": 1,\" \":0}\n",
    "\n",
    "# replacement\n",
    "for age in childAge_columns:\n",
    "    donors[age].replace(sum_dict, inplace=True)\n",
    "    \n",
    "# create a new variable named number_child that will sum the values per row under CHILD03,CHILD07, CHILD12, CHILD18 columns \n",
    "donors['number_child']= donors[childAge_columns].sum(axis=1)\n",
    "\n",
    "# replace blanks by 0's\n",
    "donors['NUMCHLD'].replace(np.nan,0.0,inplace=True)\n",
    "\n",
    "donors['NEW_NUMCHLD'] = np.where(donors['number_child']>donors['NUMCHLD'],donors['number_child'],donors['NUMCHLD'])\n",
    "#donors['NEW_NUMCHLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of values that remained the same when comparing the variable NUMCHLD and the one created\n",
    "compare_numchld_number_child = np.where(donors[\"NUMCHLD\"] == donors[\"NEW_NUMCHLD\"], True, False)\n",
    "#print(np.sum(compare_numchld_number_child *1)/len(donors)) # the percentage is 97%\n",
    "\n",
    "# shows the difference between values under the columns NEW_NUMCHLD and NUMCHLD\n",
    "#diff = donors['NEW_NUMCHLD'] - donors['NUMCHLD']\n",
    "#print(diff.value_counts()) #92040 rows are equal between the 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stay with new column, delete CHILD__ columns and auxiliar ones\n",
    "donors['NUMCHLD'] = donors['NEW_NUMCHLD']\n",
    "donors.drop(['CHILD03','CHILD07','CHILD12','CHILD18','NEW_NUMCHLD','number_child'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat column HIT in order to analyse the presence of outliers\n",
    "\n",
    "#create a boxplot for the variable HIT\n",
    "#plt.figure(figsize=(30,15))\n",
    "#sns.boxplot(y=donors[\"HIT\"])\n",
    "#plt.show()\n",
    "\n",
    "#create a histogram for the variable HIT\n",
    "#sns.set() \n",
    "#plt.figure(figsize=(30,15))\n",
    "#sns.countplot(x=donors[\"HIT\"])\n",
    "#plt.title(\"Number of times donors replied to mail order offers other than PVA\")\n",
    "#plt.show() #The hits of 32 to 241 account for a very low number of donors\n",
    "\n",
    "\n",
    "#  detect outliers manually by limiting the number of replies to 31\n",
    "filters1 = ((donors[\"HIT\"]<=31))\n",
    "my_project_noutliers = donors[filters1]\n",
    "\n",
    "# how much data is kept if we limit the number of replies to 31\n",
    "#print('Percentage of data kept after removing outliers:', np.round(my_project_noutliers.shape[0] / donors.shape[0], 4))\n",
    "\n",
    "#detect outliers manually by limiting the number of replies to 84\n",
    "#filters2 = ((donors[\"HIT\"]<=84))\n",
    "#my_project_f2 = donors[filters2]\n",
    "\n",
    "#how much data is kept if we limit the number of replies to 84\n",
    "#print('Percentage of data kept after removing outliers:', np.round(my_project_f2.shape[0] / donors.shape[0], 4))\n",
    "\n",
    "# decide on keeping only the donors who reply until 31 times\n",
    "donors= donors[filters1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_drop = filter_to_drop | (donors_original['HIT']>31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[filter_to_drop]) # 2398\n",
    "#len(donors_original[filter_to_drop])/len(donors_original) *100 #2.9378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat the column SOLP3 so it is possible to integrate the information in the column RECP3 and then delete it, this will happen by distinguishing between donors that are not in P3 program and the ones who can receive always emails\n",
    "\n",
    "#number of elements under column SOLP3 have a correspondent blank value under RECP3, meaning they represent donors who are not in P3 program.\n",
    "donors[[\"RECP3\",\"SOLP3\"]].groupby(by=[\"RECP3\"]).count()\n",
    "\n",
    "#number of blank cells under SOLP3 which can account for missing values,donors who can be mailed as many times as we want or not member of P3 program. .\n",
    "donors[\"SOLP3\"].isin([\" \"]).sum(axis=0)\n",
    "\n",
    "#index of the donors who don't belong to P3 program because they have a blank value under RECP3\n",
    "grouped= donors[[\"RECP3\",\"SOLP3\"]].groupby(by=[\"RECP3\"]).get_group(0).index\n",
    "\n",
    "#transform the values under the column SOLP3  correspondent to the above axis in -1\n",
    "solp31=donors.loc[grouped][\"SOLP3\"].replace(\" \",-1)\n",
    "\n",
    "#index of the donors who  belong to P3 program because they have a X under RECP3\n",
    "grouped1=donors[[\"RECP3\",\"SOLP3\"]].groupby(by=[\"RECP3\"]).get_group(1).index\n",
    "\n",
    "#transform the donors under SOLP3 correspondent to the above axis and assume that they can be mailed as many times as we want to the number 12\n",
    "solp32=donors.loc[grouped1][\"SOLP3\"].replace(\" \",12)\n",
    "\n",
    "#return the column SOLP3 with the necessary changes\n",
    "donors[\"SOLP3\"]=pd.concat([solp31,solp32])\n",
    "\n",
    "#confirm the values under SOLP3\n",
    "#donors[\"SOLP3\"].unique()\n",
    "\n",
    "#transform the strings in integer\n",
    "donors[\"SOLP3\"].replace({\"SOLP3\": {\"00\":0,\"12\":12,\"01\": 1,\"02\":2}}, inplace=True)\n",
    "\n",
    "#confirm the values under SOLP3\n",
    "#donors[\"SOLP3\"].unique()\n",
    "\n",
    "#drop the column RECP3\n",
    "donors.drop([\"RECP3\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat column SOLIH so it is possible to integrate the information in the column RECINHSE and then delete it, this will happen by distinguishing between donors that are not in IN House program and the ones who can receive always emails\n",
    "\n",
    "#number of elements under column SOLIH have a correspondent blank value under RECINHSE, meaning they represent donors who are not inHouse program.\n",
    "donors[[\"RECINHSE\",\"SOLIH\"]].groupby(by=[\"RECINHSE\"]).count()\n",
    "\n",
    "#index of the donors who don't belong to In House  program because they have a blank value under RECINHSE\n",
    "SOLIHg_index1= donors.loc[donors['RECINHSE']==0].index.values\n",
    "\n",
    "#transform the donors who don't belong to In House program under SOLIH in -1.\n",
    "SOLIH1=donors.loc[SOLIHg_index1][\"SOLIH\"].replace(\" \",-1)\n",
    "\n",
    "#index of the donors who  belong to In House program because they have a X under RECINHSE\n",
    "SOLIHg_index2=donors.loc[donors['RECINHSE']==1].index.values\n",
    "\n",
    "#transform the donors under SOLIH\" correspondent to the above axis and assume that they can be mailed as many times as we want to the number 12\n",
    "SOLIH2=donors.loc[SOLIHg_index2][\"SOLIH\"].replace(\" \",12)\n",
    "\n",
    "#return the column SOLIH with the necessary changes\n",
    "donors[\"SOLIH\"]=pd.concat([SOLIH1,SOLIH2])\n",
    "\n",
    "#confirm the values under SOLIH\n",
    "#donors[\"SOLIH\"].unique()\n",
    "\n",
    "#transform the strings in integer\n",
    "donors.replace({\"SOLIH\": {\"00\":0,\"12\":12,\"01\":1,\"02\":2,\"03\":3,\"04\":4,\"06\":6}}, inplace=True)\n",
    "\n",
    "#confirm the values under SOLIH\n",
    "#donors[\"SOLIH\"].unique()\n",
    "\n",
    "#drop the column RECINHSE\n",
    "donors.drop([\"RECINHSE\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEALTH1 vs INCOME\n",
    "#print('WEALTH1 -', donors['WEALTH1'].isna().sum()/len(donors)*100)\n",
    "#print('INCOME -', donors['INCOME'].isna().sum()/len(donors)*100)\n",
    "# All of the INCOME missing values are in common with WEALTH1 !\n",
    "#donors[donors['INCOME'].isna()]['WEALTH1'].isna().sum()/donors['INCOME'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors[['WEALTH1','WEALTH2']].corr(method='spearman') # highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors['WEALTH2'].isna().sum()/len(donors) *100\n",
    "# Drop WEALTH1 since it has more missing values and its very correlated with WEALTH2\n",
    "donors.drop('WEALTH1', axis=1, inplace=True)\n",
    "# Use WEALTH2 for knn imputation and then drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The following variables indicate the number of known times the donor has responded to other types of mail order offers. \n",
    "# Convert them into Y/N columns like the interests variables because anyways there are too many missing values in these HIT variables \n",
    "# (with this solution we will lose the degree of interest but its only for 50% of the data which is not a problem)\n",
    "mail_offers = list(donors.filter(regex='^MB',axis=1).columns.values) + list(donors.filter(regex='^MAG',axis=1).columns.values)+ list(donors.filter(regex='^PUB',axis=1).columns.values)\n",
    "#donors[mail_offers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mail in mail_offers: donors[mail] = donors[mail].apply(lambda x: 1 if x>0 else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Y/' ' of the interests variables into 1/0\n",
    "replaceBool_dict = {'Y': 1,' ': 0}\n",
    "interests = ['COLLECT1', 'VETERANS', 'BIBLE', 'CATLG', 'HOMEE',\n",
    "       'PETS', 'CDPLAY', 'STEREO', 'PCOWNERS', 'PHOTO', 'CRAFTS',\n",
    "       'FISHER', 'GARDENIN', 'BOATS', 'WALKER', 'KIDSTUFF', 'CARDS',\n",
    "       'PLATES']\n",
    "for interest in interests: donors[interest].replace(replaceBool_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating redundant variables regarding the donor interests and the response to an email about that interest\n",
    "##common_topics - crafts, gardening, collectables, photos, family stuff \n",
    "common_topics =[['MBCRAFT', 'CRAFTS'],['MBGARDEN','GARDENIN'],['PUBGARDN','GARDENIN'],['MBCOLECT','COLLECT1'],['MBCOLECT','PLATES'],['PUBPHOTO', 'PHOTO'],['MAGFAML','KIDSTUFF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the donor responds to an email = he has interest\n",
    "for topic in common_topics:\n",
    "        donors[topic[1]] = np.where(donors[topic[0]]==1, 1, donors[topic[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "donors.drop(mail_offers, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Treating dates from promotion and gifts history\n",
    "dates= ['ADATE_2','FISTDATE','NEXTDATE','MAXADATE','MINRDATE','MAXRDATE','LASTDATE']\n",
    "for d in dates: donors[d] = pd.to_datetime(donors[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat missing values\n",
    "#NA = donors[(donors['FISTDATE'].isna()) | (donors['NEXTDATE'].isna()) | (donors['TIMELAG'].isna())]\n",
    "#NA[['FISTDATE','NEXTDATE','TIMELAG']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_1stdate = donors.iloc[np.where(donors['FISTDATE'].isna())[0]]\n",
    "#without_1stdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really high timelags\n",
    "#for i in without_1stdate.index.values:\n",
    "#    print(relativedelta(months= without_1stdate.loc[i]['TIMELAG']))\n",
    "#    print(without_1stdate.loc[i]['NEXTDATE'] - relativedelta(months= without_1stdate.loc[i]['TIMELAG']))\n",
    "#    print(donors.loc[i][['NEXTDATE','TIMELAG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boxplot\n",
    "#plt.figure(figsize=(5,15))\n",
    "#sns.boxplot(y=donors[\"TIMELAG\"])\n",
    "#plt.show()\n",
    "\n",
    "# create a histogram\n",
    "#sns.set() \n",
    "#plt.figure(figsize=(30,15))\n",
    "#sns.countplot(x=donors[\"TIMELAG\"])\n",
    "#plt.show()\n",
    "#donors[donors[\"TIMELAG\"]>30]['TIMELAG'].value_counts() # choose min value with 2 donors - 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_highLag =(~(donors['TIMELAG']>51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_drop = filter_to_drop | (donors_original['TIMELAG']>51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[(donors_original['TIMELAG']>51)])#/len(donors_original) * 100 # 22 donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[filter_to_drop])/len(donors_original) * 100 # 2.9598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors=donors[filter_highLag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_2nddate = donors.iloc[np.where(donors['NEXTDATE'].isna())[0]]\n",
    "#without_2nddate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without_2nddate['TIMELAG'].isna().sum() # NEXTDATE and TIMELAG with nans in common  - 9790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe because this donors only have donated once ? \n",
    "\n",
    "# check if firstdate = lastdate \n",
    "#(np.where(without_2nddate['FISTDATE']==without_2nddate['LASTDATE'],True,False)*1).sum() # all have the same date\n",
    "#(np.where(donors['FISTDATE']==donors['LASTDATE'],True,False)*1).sum() #9842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneTime_donors = donors.iloc[np.where(donors['FISTDATE']==donors['LASTDATE'])][['FISTDATE','NEXTDATE','TIMELAG','LASTDATE']]\n",
    "#OneTime_donors[OneTime_donors['TIMELAG']==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors.iloc[np.where(donors['FISTDATE']==donors['LASTDATE'])]['TIMELAG'].value_counts(dropna=False) # nan - 9790, 0 - 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary variable to define one time donors \n",
    "# replace TIMELAG by 52 (max value) for one time donors\n",
    "donors['1TIME_DONOR'] = np.where(donors['FISTDATE']==donors['LASTDATE'], 1, 0)\n",
    "donors['TIMELAG'] = np.where(donors['FISTDATE']==donors['LASTDATE'], 52, donors['TIMELAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors[['FISTDATE','NEXTDATE','TIMELAG']].isna().sum() # we re not going to use nextdate so we dont need to treat the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present date \n",
    "present_date = dt.datetime.strptime('2020-09-01', '%Y-%m-%d')\n",
    "# Function to calculate the interval of time between meaningful dates (in months, as TIMELAG)\n",
    "def diff_month(d1,d2):\n",
    "    return d1.dt.month - d2.dt.month + 12*(d1.dt.year - d2.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interval between first gift and present date to understand how long the donors started to donate (this one in years)\n",
    "donors['TENURE'] = 2020 - donors['FISTDATE'].dt.year\n",
    "#donors['TENURE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop FISTDATE since it's not as informative after the feature engineering of the tenure column\n",
    "donors.drop(dates, axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the column ODATEDW as it gives information of the year when donor gave the first gift which corresponds to FISTDATE and we have created variable tenure to tell for how long the donors hare in PVA's database \n",
    "donors.drop([\"ODATEDW\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values of Data Source of Overlay Data\n",
    "donors['DATASRCE'].replace(' ', 0, inplace=True)\n",
    "donors['DATASRCE'] = donors['DATASRCE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RFA (recency/frequency/monetary) fields analysis\n",
    "RFA = ['MDMAUD_R','MDMAUD_F','MDMAUD_A','RFA_2R','RFA_2F','RFA_2A']\n",
    "\n",
    "#for column in RFA:\n",
    "#    print(donors[column].value_counts())\n",
    "\n",
    "# all lapsed donors for RFA_2 - 17NK promotion => recency is irrelevant\n",
    "donors.drop('RFA_2R', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal features with strings to numerical \n",
    "donors['RFA_2A'].replace({\"D\":0, \"E\":1, \"F\":2, \"G\":3}, inplace= True)\n",
    "donors['MDMAUD_F'].replace({\"X\":0}, inplace= True)\n",
    "donors['MDMAUD_F'].astype('int64', copy=False)\n",
    "donors['MDMAUD_A'].replace({'X':0, 'C':1, 'M':2, 'L':3, 'T':4}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat the column DOMAIN to separate the information inside each cell in two columns\n",
    "urbanicity_level_neighbourhood = [] \n",
    "socio_econ_neighbourhood= [] \n",
    " \n",
    "for i in donors[\"DOMAIN\"]: \n",
    "    urbanicity_level_neighbourhood.append(i[0]) \n",
    "    if i==' ':\n",
    "        socio_econ_neighbourhood.append(i[0]) \n",
    "    else:\n",
    "        socio_econ_neighbourhood.append(i[1]) \n",
    "\n",
    "donors[\"urbanicity_level_neighbourhood\"]=pd.DataFrame(urbanicity_level_neighbourhood, index =donors.index)\n",
    "donors[\"socio_econ_neighbourhood\"]=pd.DataFrame(socio_econ_neighbourhood, index=donors.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the blank cells with nan\n",
    "donors['socio_econ_neighbourhood'].replace({\" \":np.nan}, inplace = True)\n",
    "donors['urbanicity_level_neighbourhood'].replace({\" \":np.nan}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['urbanicity_level_neighbourhood'].replace({\"U\":0, \"C\":1, \"S\":2, \"T\":3,\"R\": 4}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['socio_econ_neighbourhood']=donors['socio_econ_neighbourhood'].astype('float')\n",
    "donors['urbanicity_level_neighbourhood']=donors['urbanicity_level_neighbourhood'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets stay with the 2 bytes separated and drop domain \n",
    "donors.drop(['DOMAIN'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDUNDANCY\n",
    "\n",
    "#check the variables that are highly correlated (more than or equal to 90%) and drop one of them to avoid redundancy\n",
    "#corr_matrix = donors.corr().abs()\n",
    "#high_corr_var=np.where(corr_matrix>=0.9)\n",
    "#high_corr_var=[(corr_matrix.columns[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "#high_corr_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can drop POP902 (no of families) and POP903 (no of households) since redundant with POP901(no. of persons)\n",
    "donors.drop(['POP902','POP903'], axis=1,inplace=True)\n",
    "\n",
    "#can drop ETHC4(%black < Age 15) & ETHC5(%black 15 - 59) since redundant with ETH2(%black)...logically, age of the \n",
    "#people in the neighbourhood will not affect the willingness of the donor to donate making this info irrelevant\n",
    "donors.drop(['ETHC4','ETHC5','ETHC6'], axis=1,inplace=True)\n",
    "\n",
    "#can drop since the ages of the races are irrelevant and we already have the info on how many white people live in the \n",
    "#neighbourhood in ETH1\n",
    "donors.drop(['ETHC1','ETHC2','ETHC3'], axis=1,inplace=True)\n",
    "\n",
    "#can drop ETH13(%mexican) & LSC2 (%spanish speaking) since redundant with ETH5(%hispanic)...hispanic includes all \n",
    "#latinos (aka spanish speaking)\n",
    "#drop all language variables due to lack of relevancy\n",
    "donors.drop(['ETH13','ETH14','ETH15','ETH16','LSC1','LSC2','LSC3','LSC4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop these Ages because, AGEC variables are more informative and disaggregated...will keep summary variables \n",
    "#AGE904 (avg age of population) and AGE907 (%population under 18)\n",
    "donors.drop(['AGE901','AGE902','AGE903','AGE905','AGE906'], axis=1,inplace=True)\n",
    "\n",
    "#can drop this children ages because they are not as relevant since don't impact decision to donate...thus we will keep\n",
    "#the CHIL variable instead since it is more aggregated\n",
    "child_list=donors.filter(regex='^CHILC',axis=1).columns.values\n",
    "donors.drop(child_list,axis=1,inplace=True)\n",
    "\n",
    "#can drop HHD1(%Households w/ Related Children) since redundant with AGE907(%Population Under Age 18) \n",
    "donors.drop('HHD1', axis=1,inplace=True)\n",
    "\n",
    "#can drop all MARR variables since once again it refers to neighbourhood not the donor himself, meaning that if my\n",
    "#neighbour is widowed, this would not affect my decision to doate to veterans\n",
    "donors.drop(['MARR1','MARR2','MARR3','MARR4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop HHAGE variables due to lack of relevancy since the ages of people in a household in a donor's neighbourhood\n",
    "#won't impact his/her decision to donate\n",
    "donors.drop(['HHAGE1','HHAGE2','HHAGE3'], axis=1,inplace=True)\n",
    "\n",
    "#can drop HHD variables because describes who lives in each household while RHP (rooms), HHP (avg & median) & HHN describes number of people per household\n",
    "#these variables refer to the neighbourhood meaning they have minimal influence on donors' decision to donate...\n",
    "#so we can drop them due to lack of relevancy\n",
    "HHD_list=donors.filter(regex='^HHD',axis=1).columns.values\n",
    "HHN_list=donors.filter(regex='^HHN',axis=1).columns.values\n",
    "donors.drop(np.concatenate([HHD_list,HHN_list]), axis=1,inplace=True)\n",
    "donors.drop(['HHP1','HHP2'], axis=1,inplace=True)\n",
    "donors.drop(['RHP1','RHP2','RHP3','RHP4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop HHAS variables which demonstrate a 'poor' neighbourhood which is also represented in IC6 (very low income)\n",
    "donors.drop(['HHAS1','HHAS2','HHAS3','HHAS4'], axis=1,inplace=True)\n",
    "\n",
    "#since DW variables refer to the style of house unit structures within neighbourhoods, this wouldn't influence donor behaviour\n",
    "#thus drop them due to lack of relevancy\n",
    "DW_list=donors.filter(regex='^DW',axis=1).columns.values\n",
    "donors.drop(DW_list, axis=1,inplace=True)\n",
    "\n",
    "#since HUPA refers to home style in neighbourhood,this wouldn't influence donor behaviour thus drop them due to lack of relevancy\n",
    "HUPA_list=donors.filter(regex='^HUPA',axis=1).columns.values\n",
    "donors.drop(HUPA_list, axis=1,inplace=True)\n",
    "\n",
    "#can drop all HV variables since it represents average and median value which is a monetary value not a percentage. This\n",
    "#is a problem because the census was created in 2010 which means the money will not have the same value today...HVP variables \n",
    "#are a better substitute\n",
    "donors.drop(['HV1','HV2','HV3','HV4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop all RP variables because HVP variables tell us more about the donor\n",
    "donors.drop(['RP1','RP2','RP3','RP4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop all HU variables except HU2 (correlated wuth HU1) because it can tell us the probability that the donor is a \n",
    "#renter or not(if he/she is a renter means they are mobile/unstable (lower family loading??) but also with more bills to pay)\n",
    "#keep HU5 to know if the neighbourhood is only a holiday one so only occassionally inhabited\n",
    "donors.drop(['HU1','HU3','HU4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop all IC variables except IC3, IC5 because average, household and per capita are more meaningful than median (especially\n",
    "#when they have the same distributions) and families\n",
    "donors.drop(['IC1','IC2','IC4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop IC15-IC23, since we will focus on households rather than families' income\n",
    "IC_list = donors.filter(regex='^IC',axis=1).columns.values[11:]\n",
    "donors.drop(IC_list, axis=1,inplace=True)\n",
    "\n",
    "#can drop all TPE variables as they are irrelevant to the donors' decision to donate (the mode of transportation of \n",
    "#the neighbourhood can hint to its income which we already have in IC variables)\n",
    "TPE_list = donors.filter(regex='^TPE',axis=1).columns.values\n",
    "donors.drop(TPE_list, axis=1,inplace=True)\n",
    "\n",
    "#can drop all LFC variables as the neighbours' employment status will not affect the donors' behaviour\n",
    "LFC_list = donors.filter(regex='^LFC',axis=1).columns.values\n",
    "donors.drop(np.delete(LFC_list,9), axis=1,inplace=True)\n",
    "\n",
    "#can drop all OCC, EIC since the type of employment of the neighbours 10 years ago will not affect the donation decision\n",
    "OCC_list = donors.filter(regex='^OCC',axis=1).columns.values\n",
    "EIC_list = donors.filter(regex='^EIC',axis=1).columns.values\n",
    "donors.drop(np.concatenate([OCC_list,EIC_list]), axis=1,inplace=True)\n",
    "\n",
    "#we will keep SEC1 & SEC2 because there is a culturalt distinction between people attending public vs private schools\n",
    "#which can affect their moral values leading to donation decision\n",
    "#can drop the rest of SEC since it does not provide enough information\n",
    "donors.drop(['SEC3','SEC4','SEC5'], axis=1,inplace=True)\n",
    "\n",
    "#can drop all AFCs and VCs except AFC1 and AFC4 because a neighbourhood with veterans & active military can be more \n",
    "#prone to donating to PVA \n",
    "donors.drop(['AFC2','AFC3','AFC5','AFC6'], axis=1,inplace=True)\n",
    "\n",
    "#can drop all VCs because which war the veterans particpated in in a donor's neighbourhood will not affect his/her \n",
    "#willingness to donate...too specific\n",
    "donors.drop(['VC1','VC2','VC3','VC4'], axis=1,inplace=True)\n",
    "\n",
    "#can drop all HC except HC15 (solar energy are environmentally friendly...aka culture of giving back)\n",
    "HC_list = donors.filter(regex='^HC',axis=1).columns.values\n",
    "donors.drop(np.delete(HC_list,14), axis=1,inplace=True)\n",
    "\n",
    "#can drop CARDPROM since redundant with NUMPROM (and NUMPROM is more informative since it includes all types of promotions)\n",
    "#we don't want to lose the information about the donors who did not receive a card promotions\n",
    "donors.drop('CARDPROM', axis=1,inplace=True)\n",
    "\n",
    "#can drop CARDGIFT since redundant with NGIFTALL (and NGIFTALL is more informative since it includes alltypes of promotions)\n",
    "donors.drop('CARDGIFT', axis=1,inplace=True)\n",
    "\n",
    "#can drop the CHIL variables since AGE907 sums them up\n",
    "donors.drop(['CHIL1','CHIL2','CHIL3'], axis=1,inplace=True)\n",
    "\n",
    "#can drop HUR1 and HUR2 because they are irrelevant (no of rooms per household per neighbourhood is too specific)\n",
    "donors.drop(['HUR1','HUR2'], axis=1,inplace=True)\n",
    "\n",
    "#can drop ADI code (Approved Driving Instructors code) because the type of driving rules followed per region in the \n",
    "#US would not affect donor behaviour\n",
    "donors.drop('ADI', axis=1,inplace=True)\n",
    "\n",
    "#can drop MC variables due to lack of relevancy especially because 2005 is too far back\n",
    "donors.drop(['MC1','MC2','MC3'], axis=1,inplace=True)\n",
    "\n",
    "# drop incoherent variables\n",
    "donors.drop(['EC1','MHUC1','MHUC2'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_metric_features = ['STATE','RECPGVG','RECSWEEP','INCOME', 'GENDER', 'WEALTH2',\n",
    "                       'DATASRCE', 'SOLP3', 'SOLIH', 'COLLECT1',\n",
    "                       'VETERANS', 'BIBLE', 'CATLG', 'HOMEE', 'PETS', 'CDPLAY', 'STEREO',\n",
    "                       'PCOWNERS', 'PHOTO', 'CRAFTS', 'FISHER', 'GARDENIN', 'BOATS',\n",
    "                       'WALKER', 'KIDSTUFF', 'CARDS', 'PLATES','PEPSTRFL','MSA','DMA',\n",
    "                       'RFA_2F', 'RFA_2A','urbanicity_level_neighbourhood', 'socio_econ_neighbourhood',\n",
    "                       'MDMAUD_R','MDMAUD_F', 'MDMAUD_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with the metric features\n",
    "all_features = list(donors.columns.values)\n",
    "for non_metric_feature in non_metric_features:\n",
    "    all_features.remove(non_metric_feature)\n",
    "metric_features = all_features\n",
    "#metric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INCOME                            22.387350\n",
       "WEALTH2                           46.281376\n",
       "MSA                                0.129606\n",
       "DMA                                0.129606\n",
       "AGE                               25.198730\n",
       "urbanicity_level_neighbourhood     2.355597\n",
       "socio_econ_neighbourhood           2.355597\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of missing values \n",
    "NA = donors.isna().mean()*100\n",
    "NA[NA!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors['MSA'].value_counts().head(10) # predominant value - 0 => lets use the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors['DMA'].value_counts().head(10) # It doesnt seem to have a predominant value but givent that we dont know the meaning/importance the mode should be efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = donors[['MSA','DMA']].mode().loc[0]\n",
    "donors.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treat high cardinality for both variables\n",
    "msa = donors['MSA'].value_counts().index[:3].tolist()\n",
    "dma = donors['DMA'].value_counts().index[:3].tolist()\n",
    "donors['MSA'] = np.where(~donors['MSA'].isin(msa), 'Other', donors['MSA'])\n",
    "donors['DMA'] = np.where(~donors['DMA'].isin(dma), 'Other', donors['DMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#donors.groupby('NUMCHLD')['AGE'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_child=[0,1,2,3,4,5,6,7]\n",
    "#for n in n_child:\n",
    "#    print(donors[donors['NUMCHLD']==n].groupby(['NUMCHLD'])['AGE'].value_counts()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace_age1 = donors.groupby(['NUMCHLD'])['AGE'].apply(lambda x: x.value_counts().index[0])\n",
    "#replace_age1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_age2 = donors.groupby(['NUMCHLD'])['AGE'].median()\n",
    "#replace_age2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors['AGE'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opt for median - create new series with the dictionary association\n",
    "AGE_CHILD = donors.NUMCHLD.replace(replace_age2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['AGE'] = np.where(pd.isnull(donors.AGE), AGE_CHILD , donors.AGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new df copy to explore neighbordhood imputation\n",
    "donors_neighbors = donors.copy()\n",
    "\n",
    "# Seeing rows with NaNs\n",
    "#nans_index = donors_neighbors.isna().any(axis=1)\n",
    "#donors_neighbors[nans_index]\n",
    "\n",
    "# KNNImputer - only works for numerical variables\n",
    "imputer = KNNImputer(n_neighbors=4, weights=\"uniform\")\n",
    "\n",
    "# to fill the missing values of INCOME, WEALTH2 and DOMAIN (socio_econ_neighbourhood and urbanicity_level_neighbourhood)\n",
    "related_variables = (['INCOME','WEALTH2','socio_econ_neighbourhood','urbanicity_level_neighbourhood', 'RFA_2A', 'MDMAUD_A', 'AVGGIFT','MAXRAMNT','MINRAMNT'] +\n",
    "                     list(donors.filter(regex='^HVP',axis=1).columns.values) +\n",
    "                     list(donors.filter(regex='^IC',axis=1).columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_neighbors[related_variables] = imputer.fit_transform(donors_neighbors[related_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop WEALTH2 after helping filling the income values\n",
    "donors_neighbors.drop('WEALTH2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See rows with NaNs imputed\n",
    "#donors_neighbors.loc[nans_index, related_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 3 1 5 2 7]\n",
      "[2 1 3 4]\n",
      "[3 2 4 0 1]\n"
     ]
    }
   ],
   "source": [
    "filled_variables= ['INCOME','socio_econ_neighbourhood','urbanicity_level_neighbourhood']\n",
    "for filled in filled_variables:\n",
    "    donors_neighbors[filled] = donors_neighbors[filled].apply(lambda x: int(x+0.5))\n",
    "    print(donors_neighbors[filled].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's keep the imputation\n",
    "donors = donors_neighbors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use OneHotEncoder to encode the categorical features as dummy variable encoding\n",
    "non_metric_encoding = ['STATE','MDMAUD_R','DATASRCE','GENDER','urbanicity_level_neighbourhood','MSA','DMA']\n",
    "ohc = OneHotEncoder(sparse=False, drop=\"first\")\n",
    "ohc_feat = ohc.fit_transform(donors[non_metric_encoding])\n",
    "ohc_feat_names = ohc.get_feature_names(['STATE','MDMAUD_R','DTSRCE','GENDER','urbanicity_level','MSA','DMA'])\n",
    "ohc_donors = pd.DataFrame(ohc_feat, index=donors.index, columns=ohc_feat_names)  \n",
    "\n",
    "donors = pd.concat([donors.drop(columns=non_metric_encoding), ohc_donors], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final outlier removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas profiling\n",
    "#ProfileReport(donors[metric_features], minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors.drop(['HVP3','HVP4','HVP5'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors[donors['POP90C4'] == 0]['POP90C5'].value_counts()\n",
    "#donors['FM'] = donors['POP90C4'] + donors['POP90C5'] \n",
    "#donors[(donors['FM']==99)][['POP90C4','POP90C5']]\n",
    "#donors.drop(['FM'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[((donors_original['POP90C4'] == 0) & (donors_original['POP90C5'] == 0))])/len(donors_original) *100 # 0.8374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_drop = filter_to_drop | ((donors_original['POP90C4'] == 0) & (donors_original['POP90C5'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = donors[((donors['POP90C4'] != 0) & (donors['POP90C5'] != 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[filter_to_drop])/len(donors_original) *100 # 3.765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors.drop(['POP90C4'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check 0's in common - 'POP901' and 'AGE904' 768 donors\n",
    "#donors[donors['POP901'] == 0]['AGE904'].unique() # empty, 0's in common with previous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors['area'] = donors['POP90C1'] + donors['POP90C2'] + donors['POP90C3']\n",
    "#donors['area'].value_counts() #99,100,101,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_drop = filter_to_drop | ((donors_original['POP90C1'] == 0) & (donors_original['POP90C2'] == 0) & (donors_original['POP90C3'] == 0))\n",
    "#len(donors_original[filter_to_drop])/len(donors_original) *100 # 3.816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = donors[donors['area']!=0]\n",
    "donors.drop(['area'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform this variables into dummies\n",
    "donors.drop(['POP90C2'], axis=1, inplace=True)\n",
    "donors['POP90C1'] = np.where(donors['POP90C1'] < 50, 0, 1)\n",
    "donors['POP90C3'] = np.where(donors['POP90C3'] < 50, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGEC_features = list(donors.filter(regex='^AGEC',axis=1).columns.values[0:4])\n",
    "#AGEC_features.append(donors.filter(regex='^AGEC',axis=1).columns.values[6])\n",
    "#for age in AGEC_features:\n",
    "#    print(donors[donors[age]>30][age].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_age = ((donors['AGEC1']>66) |\n",
    "              (donors['AGEC2']>56) |\n",
    "              (donors['AGEC3']>48) |\n",
    "              (donors['AGEC4']>34) |\n",
    "              (donors['AGEC7']>61))\n",
    "donors_2 = donors[~filter_age]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Percentage of data kept after removing outliers:', np.round(donors_2.shape[0] / donors.shape[0], 4)) #0.9974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_age_original = ((donors_original['AGEC1']>66) |\n",
    "              (donors_original['AGEC2']>56) |\n",
    "              (donors_original['AGEC3']>48) |\n",
    "              (donors_original['AGEC4']>34) |\n",
    "              (donors_original['AGEC7']>61))\n",
    "#donors_2_original = donors_original[~filter_age_original]\n",
    "#print('Percentage of data kept after removing outliers:', np.round(donors_2_original.shape[0] / donors_original.shape[0], 4)) #0.997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_drop = filter_to_drop | (filter_age_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(donors_original[filter_to_drop])/len(donors_original) * 100 #4.0697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep this alteration\n",
    "donors = donors_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['NUMCHLD','HVP3','HVP4','HVP5','POP90C1','POP90C2','POP90C3','POP90C4']\n",
    "for f in remove_features:\n",
    "    metric_features.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multivariate Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\betty\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:252: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "##### Extended Isolation Forest\n",
    "\n",
    "# matrix with values\n",
    "X = donors[metric_features].values\n",
    "\n",
    "clf = IsolationForest(n_estimators=300, random_state=42, n_jobs=-1,\n",
    "                     behaviour='new',\n",
    "                     max_samples = 'auto', contamination='auto',\n",
    "                     max_features=1.0,\n",
    "                     bootstrap=True)\n",
    "clf.fit(X)\n",
    "isolation_forest = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolation_forest_outliers = [True if x == -1 else False for x in isolation_forest]\n",
    "#sum(isolation_forest_outliers*1) # 1087 outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors2 = donors[np.logical_not(isolation_forest_outliers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_original = pd.concat([donors_original,pd.Series(isolation_forest_outliers,index=donors.index,name = 'multiOut')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.208988387204964"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_to_drop = filter_to_drop | (donors_original['multiOut'] == True)\n",
    "#len(donors_original[filter_to_drop])/len(donors_original) *100 # 5.208988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep data without multi outliers\n",
    "donors = donors2.copy()\n",
    "donors_original.drop(['multiOut'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.78786735421122"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of data kept \n",
    "#len(donors)/len(donors_original) * 100 # 94.787867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.8421052631579"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns difference (with dummies already ...)\n",
    "#donors.shape[1]/donors_original.shape[1] * 100 # 32.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donors.to_csv(r\"C:\\Users\\betty\\OneDrive\\Documentos\\donors_preprocessed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
